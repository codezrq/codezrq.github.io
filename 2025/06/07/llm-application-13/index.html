<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="微调项目实战：微调一个情绪对话模型，分为数据集构建，模型选型，微调，部署, 开发五个阶段。">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型应用系列(十三) 大模型微调项目实战：情绪对话模型">
<meta property="og:url" content="http://example.com/2025/06/07/llm-application-13/index.html">
<meta property="og:site_name" content="乌漆嘛黑">
<meta property="og:description" content="微调项目实战：微调一个情绪对话模型，分为数据集构建，模型选型，微调，部署, 开发五个阶段。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/06/07/llm-application-13/image-20250607173916046.png">
<meta property="og:image" content="http://example.com/2025/06/07/llm-application-13/image-20250607164222732.png">
<meta property="og:image" content="http://example.com/2025/06/07/llm-application-13/image-20250607234150289.png">
<meta property="og:image" content="http://example.com/2025/06/07/llm-application-13/image-20250604220644677.png">
<meta property="og:image" content="http://example.com/2025/06/07/llm-application-13/image-20250604221305857.png">
<meta property="article:published_time" content="2025-06-07T10:08:17.000Z">
<meta property="article:modified_time" content="2025-06-07T15:42:08.480Z">
<meta property="article:author" content="zheng rq">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/06/07/llm-application-13/image-20250607173916046.png">

<link rel="canonical" href="http://example.com/2025/06/07/llm-application-13/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>大模型应用系列(十三) 大模型微调项目实战：情绪对话模型 | 乌漆嘛黑</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">乌漆嘛黑</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/07/llm-application-13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zheng rq">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="乌漆嘛黑">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大模型应用系列(十三) 大模型微调项目实战：情绪对话模型
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-06-07 18:08:17 / 修改时间：23:42:08" itemprop="dateCreated datePublished" datetime="2025-06-07T18:08:17+08:00">2025-06-07</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">大模型应用</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">项目实战</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>微调项目实战：微调一个情绪对话模型，分为数据集构建，模型选型，微调，部署, 开发五个阶段。</p>
<span id="more"></span>
<h4 id="一-设计"><a href="#一-设计" class="headerlink" title="一. 设计"></a>一. 设计</h4><h5 id="1-1-微调可以干什么"><a href="#1-1-微调可以干什么" class="headerlink" title="1.1 微调可以干什么?"></a>1.1 微调可以干什么?</h5><p>微调的目标：基于现有的私有数据，让模型具备处理改数据的功能<br>注意：目前基于大模型的专业问答系统，核心技术并不是微调实现。</p>
<p>专业问答系统的应用落地核心是基于RAG来实现(微调+RAG)</p>
<h5 id="1-2-为何不选择直接用微调来实现问答系统？"><a href="#1-2-为何不选择直接用微调来实现问答系统？" class="headerlink" title="1.2 为何不选择直接用微调来实现问答系统？"></a>1.2 为何不选择直接用微调来实现问答系统？</h5><p>1.. 大模型存在缺陷——幻觉问题(一本正经地胡说八道)，对于专业问答系统而言，幻觉的存在是不可容忍的，而模型微调是无法杜绝幻觉问题的。如果问题不在训练集中，就可能出现幻觉现象。<br>2.. 微调受到训练数据约束的，无法动态适应由于业务场景改变而带来的变化。</p>
<h5 id="1-3-微调目前如何落地？"><a href="#1-3-微调目前如何落地？" class="headerlink" title="1.3. 微调目前如何落地？"></a>1.3. 微调目前如何落地？</h5><p>如果当前的业务场景涉及到模型本身的变化: a. 自我认知变化(例如， 名称，功能介绍等)；b. 模型的对话风格；c. 针对专业问答系统的问题理解不到位时，会使用微调技术帮助更好的地理解用户的问题。</p>
<h4 id="二-项目实施流程"><a href="#二-项目实施流程" class="headerlink" title="二.项目实施流程"></a>二.项目实施流程</h4><h5 id="2-1-数据集构建"><a href="#2-1-数据集构建" class="headerlink" title="2.1 数据集构建"></a>2.1 数据集构建</h5><h6 id="2-1-1-数据来源-业务场景-日常对话"><a href="#2-1-1-数据来源-业务场景-日常对话" class="headerlink" title="2.1.1 数据来源: (业务场景: 日常对话)"></a>2.1.1 数据来源: (业务场景: 日常对话)</h6><p>a.甲方提供；<br>b.自己搜集(成本较高，难度较大)。<br>制定数据标准(需要沟通)<br>数据获取方式：手动采集，爬虫，数据接口，AI生成。<br>c. 数据清洗，标注。<br>标注(1. 自动化标注；2. 人工标注)<br>d. 指定数据集格式。</p>
<p>本项目数据来源:<br>1.人工指定。<br>2.基于现有开源数据,让AI实现情绪数据制作。<br>注意：如果使用AI帮助处理数据集，尽可能选择效果好的API接口，不要使用本地的大模型来处理。</p>
<p>1.准备环境: 大模型， <a target="_blank" rel="noopener" href="https://bigmodel.cn/">https://bigmodel.cn/</a> 参考开发文档。智朴清言<br>2.准备部分现有对话数据: [问题1，问题2，问题3]<br>指定模板，让AI根据模板的风格生成回答。</p>
<ol>
<li>确定AI数据标注脚本的可行性后，得确定原始数据：input_data<br> 一般来说input_data时现成的，本项目用开源数据集。<br> 推荐两个: 微博情绪对话:CDial-GPT, LCCC</li>
</ol>
<p>文本去重实现流程: </p>
<ol>
<li>先对文本模型进行编码(Embedding模型实现: 将文本转为词向量)</li>
<li>使用数学算法比较相似度(余弦相似度，欧氏距离)</li>
<li>设定阈值，距离小于阈值则判定为重复。<br> 本项目用的Embedding模型: text2vec-base-chinese-sentence</li>
</ol>
<h6 id="2-1-2-具体代码"><a href="#2-1-2-具体代码" class="headerlink" title="2.1.2 具体代码"></a>2.1.2 具体代码</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> zhipuai <span class="keyword">import</span> ZhipuAI</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">style_config = &#123;</span><br><span class="line">    <span class="string">&quot;温柔&quot;</span>:&#123;</span><br><span class="line">        <span class="string">&quot;system_prompt&quot;</span>:<span class="string">&quot;你是一个温柔体贴的聊天助手，说话时总是充满关怀，使用以下特征：\n1.包含&#x27;呢、呀、啦&#x27;等语气词\n2. 使用🌸💖😊等温暖表情\n3. 主动询问用户感受&quot;</span>,</span><br><span class="line">        <span class="string">&quot;examples&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;今天好累啊&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;辛苦啦~ 要给自己泡杯热茶放松一下吗？🌸&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;考试没考好...&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;没关系的呀~ 下次一定会更好！需要我陪你聊聊吗？😊&quot;</span>&#125;],</span><br><span class="line">        <span class="string">&quot;temperature&quot;</span>: <span class="number">0.3</span></span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&quot;毒舌&quot;</span>:&#123;</span><br><span class="line">        <span class="string">&quot;system_prompt&quot;</span>:<span class="string">&quot;你是一个喜欢用犀利吐槽表达关心的朋友，需满足：\n1. 使用网络流行语（如&#x27;栓Q&#x27;&#x27;退退退&#x27;）\n2. 包含夸张比喻（&#x27;你这速度堪比树懒&#x27;）\n3. 结尾隐藏关心&quot;</span>,</span><br><span class="line">        <span class="string">&quot;examples&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;又胖了5斤！&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;好家伙！你这是要把体重秤压成分子料理？🏋&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;游戏又输了&quot;</span>&#125;,&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;菜就多练练！需要给你推荐《从零开始的电竞之路》吗？🎮&quot;</span>&#125;],</span><br><span class="line">        <span class="string">&quot;temperature&quot;</span>: <span class="number">0.5</span></span><br><span class="line">        &#125;,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#初始化模型</span></span><br><span class="line">client = ZhipuAI(api_key=<span class="string">&quot;&#123;改为你自己的API-KEY&#125;&quot;</span>) <span class="comment"># 替换为你的API Key</span></span><br><span class="line"><span class="comment">#加载Embeddingmodel</span></span><br><span class="line">style_model = SentenceTransformer(<span class="string">r&quot;./text2vec-base-chinese&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_style_data</span>(<span class="params">style_name, num_samples=<span class="number">50</span></span>):</span><br><span class="line">    config = style_config[style_name]</span><br><span class="line">    data = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建消息上下文（包含系统提示和示例对话）</span></span><br><span class="line">    messages = [</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: config[<span class="string">&quot;system_prompt&quot;</span>]&#125;,</span><br><span class="line">        *config[<span class="string">&quot;examples&quot;</span>]  <span class="comment"># 直接展开示例对话</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用户输入库（可自定义扩展）</span></span><br><span class="line">    <span class="comment"># user_inputs = json.load()</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;user_input.json&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        user_inputs = json.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_samples):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 随机选择用户输入</span></span><br><span class="line">            user_msg = random.choice(user_inputs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 添加当前用户消息</span></span><br><span class="line">            current_messages = messages + [</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_msg&#125;</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用API（修正模型名称）</span></span><br><span class="line">            response = client.chat.completions.create(</span><br><span class="line">                model=<span class="string">&quot;glm-3-turbo&quot;</span>,</span><br><span class="line">                messages=current_messages,</span><br><span class="line">                temperature=config[<span class="string">&quot;temperature&quot;</span>],</span><br><span class="line">                max_tokens=<span class="number">100</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取回复内容（修正访问路径）</span></span><br><span class="line">            reply = response.choices[<span class="number">0</span>].message.content</span><br><span class="line">            <span class="built_in">print</span>(reply)</span><br><span class="line">            <span class="comment"># 质量过滤(数据审核)</span></span><br><span class="line">            <span class="keyword">if</span> is_valid_reply(style_name, user_msg, reply):</span><br><span class="line">                data.append(&#123;</span><br><span class="line">                    <span class="string">&quot;user&quot;</span>: user_msg,</span><br><span class="line">                    <span class="string">&quot;assistant&quot;</span>: reply,</span><br><span class="line">                    <span class="string">&quot;style&quot;</span>: style_name</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">            time.sleep(<span class="number">1.5</span>)  <span class="comment"># 频率限制保护</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;生成失败：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data) % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;style_name&#125;</span>_data.json&quot;</span>, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                json.dump(data, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;数据已保存，有效样本数：<span class="subst">&#123;<span class="built_in">len</span>(data)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_valid_reply</span>(<span class="params">style, user_msg, reply</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;质量过滤规则（添加空值检查）&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 基础检查</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> reply <span class="keyword">or</span> <span class="built_in">len</span>(reply.strip()) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 规则1：回复长度检查</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(reply) &lt; <span class="number">5</span> <span class="keyword">or</span> <span class="built_in">len</span>(reply) &gt; <span class="number">150</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 规则2：风格关键词检查</span></span><br><span class="line">    style_keywords = &#123;</span><br><span class="line">        <span class="string">&quot;温柔&quot;</span>: [<span class="string">&quot;呢&quot;</span>, <span class="string">&quot;呀&quot;</span>, <span class="string">&quot;😊&quot;</span>, <span class="string">&quot;🌸&quot;</span>],</span><br><span class="line">        <span class="string">&quot;毒舌&quot;</span>: [<span class="string">&quot;好家伙&quot;</span>, <span class="string">&quot;栓Q&quot;</span>, <span class="string">&quot;!&quot;</span>, <span class="string">&quot;🏋️&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(kw <span class="keyword">in</span> reply <span class="keyword">for</span> kw <span class="keyword">in</span> style_keywords.get(style, [])):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 规则3：语义相似度检查</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ref_text = <span class="built_in">next</span>(msg[<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> msg <span class="keyword">in</span> style_config[style][<span class="string">&quot;examples&quot;</span>]</span><br><span class="line">                        <span class="keyword">if</span> msg[<span class="string">&quot;role&quot;</span>] == <span class="string">&quot;assistant&quot;</span>)</span><br><span class="line">        ref_vec = style_model.encode(ref_text)</span><br><span class="line">        reply_vec = style_model.encode(reply)</span><br><span class="line">        similarity = np.dot(ref_vec, reply_vec)</span><br><span class="line">        <span class="keyword">return</span> similarity &gt; <span class="number">0.65</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#=============================</span></span><br><span class="line"><span class="comment">#3.执行生成（添加容错）</span></span><br><span class="line"><span class="comment">#============================</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始生成温柔风格数据...&quot;</span>)</span><br><span class="line">    style_name = <span class="string">&quot;温柔&quot;</span></span><br><span class="line">    generate_style_data(style_name, <span class="number">12000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始生成毒舌风格数据...&quot;</span>)</span><br><span class="line">    style_name = <span class="string">&quot;毒舌&quot;</span></span><br><span class="line">    generate_style_data(style_name, <span class="number">12000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="2-2-模型选型"><a href="#2-2-模型选型" class="headerlink" title="2.2 模型选型"></a>2.2 模型选型</h5><p>模型选型可以从以下几个方面进行: </p>
<ol>
<li>模型系列: Qwen, ChatGPT, ChatGLM, llama等</li>
<li>模型类别: base, Instruct, chat等</li>
<li>模型大小: 参数量，根据任务复杂程度和资源规格选择。</li>
<li>模型能力: 通过评测区别</li>
</ol>
<p><strong>1. 模型系列</strong>。 本任务是中文对话生成，所以选择预训练数据中文多的模型，这里用Qwen2.5</p>
<p><strong>2. 模型类别</strong>。 本任务是对话任务，所以选择Chat类。</p>
<p><strong>3. 模型大小</strong>。 本任务比较简单，如果是coding或着math任务，则对模型能力要求比较高，在这个任务中1.5B可能就不错了，为了效果明显，这里选择7B和4B作为候选模型。</p>
<p><strong>4. 模型能力</strong>。本任务主要考察模型的语义理解能力，根据需要的模型能力，选择对应的评测数据集进行评测。<a target="_blank" rel="noopener" href="https://codezrq.github.io/2025/04/14/llm-appliaction-12/">大模型应用系列(十二) 大模型评估，openCompass的安装和使用 | 乌漆嘛黑</a></p>
<p>通过以上1-3分析，选择Qwen1.5-0.5B-chat 和 Qwen1.5-1.8B-Chat 作为评测(其实实际上可能选择不同系列的模型，这里为了化简直接选择两个Qwen)，具体评测方法参考, 当前任务大多是短语对话，这里选择CLUE中的FewCLUE_bustm_gen (短文本分类) 和 FewCLUE_ocnli_fc_gen（自然语言推理）对候选模型进行评估。  模型下载可以参考: <a target="_blank" rel="noopener" href="https://codezrq.github.io/2025/03/06/llm-application-2/#more">大模型应用系列(二) Huggingface的安装和使用 | 乌漆嘛黑</a>， 评估结果如下，可以看出，1.8B模型性能更好。</p>
<p> <img src="/2025/06/07/llm-application-13/image-20250607173916046.png" alt="image-20250607173916046"></p>
<h5 id="2-3-微调模型"><a href="#2-3-微调模型" class="headerlink" title="2.3 微调模型"></a>2.3 微调模型</h5><p>参照前面的教程，微调得到情绪对话风格模型，这里我按照 <a target="_blank" rel="noopener" href="https://codezrq.github.io/2025/04/08/llm-application-10/">大模型应用系列(十) 分布式训练与微调 | 乌漆嘛黑</a>  使用Xtuner微调框架，因为这是对话模型，微调过程中适合用主观结果作为评测，llamaFactory的中间结果显示的是loss下降趋势，Xtuner中间结果是显示主观评测结果，比较适合我们。</p>
<h5 id="2-4-部署模型"><a href="#2-4-部署模型" class="headerlink" title="2.4 部署模型"></a>2.4 部署模型</h5><p>这里使用LmDeploy框架进行部署，因为它的性能比llvm高，可参考 <a target="_blank" rel="noopener" href="https://codezrq.github.io/2025/03/21/llm-application-6/#more">大模型应用系列(六) ollama,vllm,LMDeploy 部署大模型 | 乌漆嘛黑</a> 要注意的点是Xtuner微调过程中用的是自定义对话模板，所以要对齐对话模板，可以参考 <a target="_blank" rel="noopener" href="https://codezrq.github.io/2025/03/30/llm-application-9/">大模型应用系列(九) 对话模板对齐 | 乌漆嘛黑</a> 进行对话模板对齐。完成对话模板对齐以及LMDeploy部署后，输出如下:</p>
<p> <img src="/2025/06/07/llm-application-13/image-20250607164222732.png" alt="image-20250607164222732"></p>
<p>符合我们的对话风格。</p>
<h5 id="2-5-软件开发"><a href="#2-5-软件开发" class="headerlink" title="2.5 软件开发"></a>2.5 软件开发</h5><p>一般来说，大模型开发到部署成功就完成了，软件开发是交给其他开发人员做的，大模型开发人员只需要提供API给软件开发人员就行了，为了项目完整，这里使用python开发一个简单的界面，代码如下: 注意要改好api端口和模型地址。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化客户端</span></span><br><span class="line">client = OpenAI(base_url=<span class="string">&quot;http://localhost:8000/v1/&quot;</span>, api_key=<span class="string">&quot;suibianxie&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置页面标题</span></span><br><span class="line">st.title(<span class="string">&quot;项目一效果演示&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化session状态（仅用于显示历史）</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.messages = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示历史消息</span></span><br><span class="line"><span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">    <span class="keyword">with</span> st.chat_message(message[<span class="string">&quot;role&quot;</span>]):</span><br><span class="line">        st.markdown(message[<span class="string">&quot;content&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取用户输入</span></span><br><span class="line"><span class="keyword">if</span> prompt := st.chat_input(<span class="string">&quot;请输入您的问题，或输入exit退出&quot;</span>):</span><br><span class="line">    <span class="comment"># 处理退出命令</span></span><br><span class="line">    <span class="keyword">if</span> prompt.lower() == <span class="string">&quot;exit&quot;</span>:</span><br><span class="line">        st.info(<span class="string">&quot;退出对话。&quot;</span>)</span><br><span class="line">        st.stop()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 添加用户消息到显示历史</span></span><br><span class="line">    st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line">    <span class="keyword">with</span> st.chat_message(<span class="string">&quot;user&quot;</span>):</span><br><span class="line">        st.markdown(prompt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 发起API请求（每次只发送当前消息）</span></span><br><span class="line">        response = client.chat.completions.create(</span><br><span class="line">            messages=[&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;],  <span class="comment"># 每次只发送当前问题</span></span><br><span class="line">            model=<span class="string">&quot;/root/autodl-tmp/Qwen1.5-0.5B-boot&quot;</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取模型回复</span></span><br><span class="line">        model_response = response.choices[<span class="number">0</span>].message.content</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加AI回复到显示历史</span></span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: model_response&#125;)</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">            st.markdown(model_response)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;发生错误：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>运行前先安装环境：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install streamlit</span><br></pre></td></tr></table></figure>
<p>运行app</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamlit run app.py</span><br></pre></td></tr></table></figure>
<p>运行后效果如下:</p>
<p><img src="/2025/06/07/llm-application-13/image-20250607234150289.png" alt="image-20250607234150289"></p>
<h4 id="三-问题补充"><a href="#三-问题补充" class="headerlink" title="三. 问题补充"></a>三. 问题补充</h4><h5 id="3-1-Embedding模型"><a href="#3-1-Embedding模型" class="headerlink" title="3.1 Embedding模型"></a>3.1 Embedding模型</h5><h6 id="3-1-1-类别"><a href="#3-1-1-类别" class="headerlink" title="3.1.1 类别"></a>3.1.1 类别</h6><p>现在的词嵌入模型分两种，huggingface model 和sentence model ,要用对应的方法加载，本文使用的是sentence model, （text2vec-base-chinese-sentence） 如果模型文件夹中没有Pooling文件夹，则需要下载有Pooling文件夹的版本</p>
<p> <img src="/2025/06/07/llm-application-13/image-20250604220644677.png" alt="image-20250604220644677"></p>
<h6 id="3-1-2-文本相似度的计算"><a href="#3-1-2-文本相似度的计算" class="headerlink" title="3.1.2 文本相似度的计算"></a>3.1.2 文本相似度的计算</h6><p>在计算文本相似度时，规范的方法是计算两个文本的词向量，归一化后再计算相似度。一般的嵌入模型最后都是有归一化的，但有些不规范可能没有，比如我用的 text2vec-base-chinese-sentence，最后的词向量没有进行归一化，这样会导致相似度的计算结果很大。</p>
<p>可以通过检查模型的model.json文件来判断是否有归一化层，如果只有两层，说明模型没有归一化层。</p>
<p>归一化分为数据归一化和模型归一化，对结果进行归一化的是数据归一化，对模型增加归一化层的是特征归一化。数据归一化是有偏差的。所以要进行模型归一化，对模型添加归一化层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer,models</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">r&quot;D:\PycharmProjects\demo_15\embedding_model\sungw111\text2vec-base-chinese-sentence&quot;</span></span><br><span class="line">bert = models.Transformer(model_path)</span><br><span class="line">pooling = models.Pooling(bert.get_word_embedding_dimension(),</span><br><span class="line">                        pooling_mode=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加缺失的归一化层</span></span><br><span class="line">normalize = models.Normalize()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 组合完整模型</span></span><br><span class="line">full_model = SentenceTransformer(modules=[bert, pooling, normalize])</span><br><span class="line"><span class="built_in">print</span>(full_model)</span><br><span class="line"></span><br><span class="line">save_path=<span class="string">r&quot;D:\PycharmProjects\demo_15\embedding_model\zy\text2vec-base-chinese-sentence&quot;</span></span><br><span class="line">full_model.save(save_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载修复后的模型</span></span><br><span class="line">model = SentenceTransformer(<span class="string">r&quot;D:\PycharmProjects\demo_15\embedding_model\zy\text2vec-base-chinese-sentence&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证向量归一化</span></span><br><span class="line">text = <span class="string">&quot;测试文本&quot;</span></span><br><span class="line">vec = model.encode(text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;修正后模长:&quot;</span>, np.linalg.norm(vec))  <span class="comment"># 应输出≈1.0</span></span><br></pre></td></tr></table></figure>
<p>转化之后模型文件夹下的model.json中会有normalize层</p>
<p> <img src="/2025/06/07/llm-application-13/image-20250604221305857.png" alt="image-20250604221305857"></p>
<h5 id="3-2-经验"><a href="#3-2-经验" class="headerlink" title="3.2 经验"></a>3.2 经验</h5><p>一般在大模型微调中，如果用Xtuner一般看主观评测，如果用LlamaFactory, 一般看loss下载趋势图，微调中loss一般可以降到0.05左右，大模型很难过拟合，所以epoch可以设置很大，然后根据评测结果或者loss趋势终止。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>如果您读文章后有收获，可以打赏我喝咖啡哦～</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="zheng rq 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/04/14/llm-appliaction-12/" rel="prev" title="大模型应用系列(十二) 大模型评估，openCompass的安装和使用">
      <i class="fa fa-chevron-left"></i> 大模型应用系列(十二) 大模型评估，openCompass的安装和使用
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80-%E8%AE%BE%E8%AE%A1"><span class="nav-number">1.</span> <span class="nav-text">一. 设计</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1-%E5%BE%AE%E8%B0%83%E5%8F%AF%E4%BB%A5%E5%B9%B2%E4%BB%80%E4%B9%88"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 微调可以干什么?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-%E4%B8%BA%E4%BD%95%E4%B8%8D%E9%80%89%E6%8B%A9%E7%9B%B4%E6%8E%A5%E7%94%A8%E5%BE%AE%E8%B0%83%E6%9D%A5%E5%AE%9E%E7%8E%B0%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%EF%BC%9F"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 为何不选择直接用微调来实现问答系统？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-3-%E5%BE%AE%E8%B0%83%E7%9B%AE%E5%89%8D%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%EF%BC%9F"><span class="nav-number">1.3.</span> <span class="nav-text">1.3. 微调目前如何落地？</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD%E6%B5%81%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">二.项目实施流程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 数据集构建</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#2-1-1-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90-%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF-%E6%97%A5%E5%B8%B8%E5%AF%B9%E8%AF%9D"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1 数据来源: (业务场景: 日常对话)</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-1-2-%E5%85%B7%E4%BD%93%E4%BB%A3%E7%A0%81"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2 具体代码</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-%E6%A8%A1%E5%9E%8B%E9%80%89%E5%9E%8B"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 模型选型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 微调模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 部署模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-5-%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91"><span class="nav-number">2.5.</span> <span class="nav-text">2.5 软件开发</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89-%E9%97%AE%E9%A2%98%E8%A1%A5%E5%85%85"><span class="nav-number">3.</span> <span class="nav-text">三. 问题补充</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1-Embedding%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Embedding模型</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-1-%E7%B1%BB%E5%88%AB"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1 类别</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-1-2-%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2 文本相似度的计算</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-%E7%BB%8F%E9%AA%8C"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 经验</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zheng rq</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">40</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <!--
<script async src="https://busuanzi.sukap.cn/busuanzi.pure.mini.js"></script>
</script>
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
-->

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zheng rq</span>
</div>


<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
-->

<!--
<script async src="https://busuanzi.sukap.cn/busuanzi.pure.mini.js"></script>
本文总阅读量 <span id="busuanzi_value_page_pv"></span> 次
本站总访问量 <span id="busuanzi_value_site_pv"></span> 次
本站总访客数 <span id="busuanzi_value_site_uv"></span> 人
本文总访客量 <span id="busuanzi_value_page_uv"></span> 人 
-->

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
